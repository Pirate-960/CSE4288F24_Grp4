{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy matplotlib scipy pandas seaborn scikit-learn statsmodels plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report, \n",
    "                           roc_auc_score, roc_curve)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_json_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return pd.DataFrame(json.load(file))\n",
    "\n",
    "# Load datasets\n",
    "train_data = load_json_data('train_processed.json')\n",
    "development_data = load_json_data('dev_processed.json')\n",
    "test_data = load_json_data('test_processed.json')\n",
    "\n",
    "# Extract features and labels for all datasets\n",
    "def prepare_features_and_labels(data, vectorizer=None):\n",
    "    if vectorizer is None:\n",
    "        vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "        features = vectorizer.fit_transform(data['text'])\n",
    "    else:\n",
    "        features = vectorizer.transform(data['text'])\n",
    "    labels = data['labels']\n",
    "    return features, labels, vectorizer\n",
    "\n",
    "# Prepare features and labels\n",
    "X_train, y_train, vectorizer = prepare_features_and_labels(train_data)\n",
    "X_dev, y_dev, _ = prepare_features_and_labels(development_data, vectorizer)\n",
    "X_test, y_test, _ = prepare_features_and_labels(test_data, vectorizer)\n",
    "\n",
    "# Combine training and development data for final model training\n",
    "X_combined = np.vstack([X_train.toarray(), X_dev.toarray()])\n",
    "y_combined = np.hstack([y_train, y_dev])\n",
    "\n",
    "# Train Naive Bayes model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_combined, y_combined)\n",
    "\n",
    "# Model Evaluation\n",
    "predictions = model.predict(X_test)\n",
    "probabilities = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "class_report = classification_report(y_test, predictions, target_names=['Class 0', 'Class 1'])\n",
    "roc_auc = roc_auc_score(y_test, probabilities)\n",
    "\n",
    "# Cross-Validation (for robustness)\n",
    "cross_val_scores = cross_val_score(model, X_combined, y_combined, cv=5, scoring='accuracy')\n",
    "\n",
    "# Feature Importance Analysis\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': model.feature_log_prob_[1] - model.feature_log_prob_[0]  # Log probability ratio\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "# Visualizations\n",
    "# 1. Confusion Matrix Heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Class 0', 'Class 1'], \n",
    "            yticklabels=['Class 0', 'Class 1'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# 2. ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, probabilities)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 3. Top Features Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_features = feature_importance.head(20)\n",
    "sns.barplot(data=top_features, x='importance', y='feature')\n",
    "plt.title('Top 20 Most Important Features')\n",
    "plt.xlabel('Log Probability Ratio')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save processed datasets\n",
    "train_data.to_json('processed_training_dataset.json', orient='records', force_ascii=False)\n",
    "development_data.to_json('processed_development_dataset.json', orient='records', force_ascii=False)\n",
    "test_data.to_json('processed_testing_dataset.json', orient='records', force_ascii=False)\n",
    "\n",
    "# Save feature importance analysis\n",
    "feature_importance.to_csv('feature_importance.csv', index=False)\n",
    "\n",
    "# Performance Summary\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Cross-Validation Scores:\", cross_val_scores)\n",
    "print(f\"Mean CV Accuracy: {np.mean(cross_val_scores):.2f}\")\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Print top discriminative features\n",
    "print(\"\\nTop 10 Most Discriminative Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
